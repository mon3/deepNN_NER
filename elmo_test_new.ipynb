{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "elmo_test_new.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mon3/deepNN_NER/blob/master/elmo_test_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "r5k3A6IBOlWe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q pydrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QcK_l5YLyjok",
        "colab_type": "code",
        "outputId": "14d09b38-f439-42f6-9101-fb458ea4469f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FyxR3hxEOnch",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MPzHW796AQau",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "your_module = drive.CreateFile({'id':'1lBy0_BsIQ_gzuCkM-P4MWbstIZFkHj8L'})\n",
        "your_module.GetContentFile('preprocess.py')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SL1sOrhjkcdZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prepro_elmo_module = drive.CreateFile({'id':'1S_fLdw31wQMBtIqIzEIelYlLim4A8dxA'})\n",
        "prepro_elmo_module.GetContentFile('elmo_preprocessing1.py')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cRqpT7ciZY5j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prepro_elmo_module1 = drive.CreateFile({'id':'1jK137fvsVr_DO7UiEA9J0Qbx_LLm7XPS'})\n",
        "prepro_elmo_module1.GetContentFile('elmo_prep11.py')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_I6N-2GkA-l3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "validation_module = drive.CreateFile({'id': '1nEox1MVwcpP3Fu5RGJzhKi358x9jTA2h'})\n",
        "validation_module.GetContentFile('validation.py')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nb4L3wr2jq4c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prepro_elmo_module2 = drive.CreateFile({'id':'1gmJJScIBfWmOdDMzOJO2kZvHb-r0zJpG'})\n",
        "prepro_elmo_module2.GetContentFile('elmo_prep4.py')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QdmP1G75z_ED",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prepro_elmo_module3 = drive.CreateFile({'id':'1v9lb4SlclxAAKYjIRk0lrYp5oP3WEU3J'})\n",
        "prepro_elmo_module3.GetContentFile('elmo_preprocess_sentences_nontrain.py')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yzjtx0HjGRHv",
        "colab_type": "code",
        "outputId": "0447a3c0-ba17-4161-9afe-8896a9f3f9a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Load packages\"\"\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from validation import compute_f1\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import TimeDistributed, Conv1D, Dense, Embedding, Input, Dropout, LSTM, Bidirectional, MaxPooling1D, \\\n",
        "    Flatten, concatenate, Lambda\n",
        "#from preprocess import readfile, addCharInformation, padding\n",
        "from elmo_preprocess_sentences_nontrain import createMatrices, createBatches, createBatchesNonTrain, iterate_minibatches, readfile, addCharInformation, padding\n",
        "from keras.utils import plot_model\n",
        "from keras.initializers import RandomUniform\n",
        "from keras.optimizers import SGD, Nadam\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0402 22:12:53.736550 139698042873728 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "xdX6Eqh-BfKz",
        "colab_type": "code",
        "outputId": "219bd2f9-4bab-458e-931b-05fc1930508b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Set parameters\"\"\"\n",
        "\n",
        "EPOCHS = 80               # paper: 80\n",
        "DROPOUT = 0.68           # paper: 0.68\n",
        "DROPOUT_RECURRENT = 0.0  # not specified in paper, 0.25 recommended; in other papers: 0.0\n",
        "LSTM_STATE_SIZE = 275    # paper: 275\n",
        "CONV_SIZE = 3             # paper: 3\n",
        "LEARNING_RATE = 0.0105    # paper 0.0105\n",
        "OPTIMIZER = Nadam()       # paper uses SGD(lr=self.learning_rate), Nadam() recommended\n",
        "LOCATION_POINTER = '/content/gdrive/My Drive/masters_thesis/'\n",
        "CHAR_EMBEDDING = 30   # paper: 25, previously: 30\n",
        "VERSION = 16\n",
        "EMBEDDING = \"elmo\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0402 22:12:56.036170 139698042873728 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "X1J6puMBBYJ4",
        "colab_type": "code",
        "outputId": "35f5813b-38de-4c09-acdf-10a89ce387e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Initialise class\"\"\"\n",
        "\n",
        "class CNN_BLSTM(object):\n",
        "    \n",
        "    def __init__(self, EPOCHS, DROPOUT, DROPOUT_RECURRENT, LSTM_STATE_SIZE, CONV_SIZE, LEARNING_RATE, OPTIMIZER, CHAR_EMBEDDING, VERSION, EMBEDDING):\n",
        "        \n",
        "        self.epochs = EPOCHS\n",
        "        self.dropout = DROPOUT\n",
        "        self.dropout_recurrent = DROPOUT_RECURRENT\n",
        "        self.lstm_state_size = LSTM_STATE_SIZE\n",
        "        self.conv_size = CONV_SIZE\n",
        "        self.learning_rate = LEARNING_RATE\n",
        "        self.optimizer = OPTIMIZER\n",
        "        self.char_embedding_size = CHAR_EMBEDDING\n",
        "        self.version = VERSION\n",
        "        self.embedding = EMBEDDING\n",
        "#         self.tokens_length = []\n",
        "        \n",
        "    def loadData(self):\n",
        "        \"\"\"Load data and add character information\"\"\"\n",
        "        self.trainSentences = readfile(os.path.join(LOCATION_POINTER, \"data/train.txt\"))\n",
        "        self.devSentences = readfile(os.path.join(LOCATION_POINTER, \"data/dev.txt\"))\n",
        "        self.testSentences = readfile(os.path.join(LOCATION_POINTER, \"data/test.txt\"))\n",
        "\n",
        "    def addCharInfo(self):\n",
        "        # format: [['EU', ['E', 'U'], 'B-ORG\\n'], ...]\n",
        "        self.trainSentences = addCharInformation(self.trainSentences)\n",
        "        self.devSentences = addCharInformation(self.devSentences)\n",
        "        self.testSentences = addCharInformation(self.testSentences)\n",
        "\n",
        "    def embed(self):\n",
        "        \"\"\"Create word- and character-level embeddings\"\"\"\n",
        "\n",
        "        labelSet = set()\n",
        "        words = {}\n",
        "\n",
        "        # unique words and labels in data  \n",
        "        for dataset in [self.trainSentences, self.devSentences, self.testSentences]:\n",
        "            for sentence in dataset:\n",
        "                for token, char, label in sentence:\n",
        "                    # token ... token, char ... list of chars, label ... BIO labels   \n",
        "                    labelSet.add(label)\n",
        "                    words[token.lower()] = True\n",
        "                    \n",
        "        # mapping for labels\n",
        "        self.label2Idx = {}\n",
        "        for label in labelSet:\n",
        "            self.label2Idx[label] = len(self.label2Idx)\n",
        "\n",
        "        # mapping for token cases\n",
        "        case2Idx = {'numeric': 0, 'allLower': 1, 'allUpper': 2, 'initialUpper': 3, 'other': 4, 'mainly_numeric': 5,\n",
        "                    'contains_digit': 6, 'PADDING_TOKEN': 7}\n",
        "        # creates identity matrix for token cases\n",
        "        self.caseEmbeddings = np.identity(len(case2Idx), dtype='float32')  # identity matrix used \n",
        "\n",
        "        # read GLoVE word embeddings\n",
        "        word2Idx = {}\n",
        "#         self.wordEmbeddings = []\n",
        "        \n",
        "#         word represented as 50-dim vector\n",
        "#         ToDO: test with 300-dim vectors (GloVE 42B, GloVE 84B)\n",
        "#         if self.embedding == \"fastText\":\n",
        "#           fEmbeddings = open(os.path.join(LOCATION_POINTER, \"embeddings/wiki-news-300d-1M.vec\"), encoding=\"utf-8\")\n",
        "#         else:\n",
        "#           fEmbeddings = open(os.path.join(LOCATION_POINTER, \"embeddings/glove.6B.50d.txt\"), encoding=\"utf-8\")\n",
        "\n",
        "#         # loop through each word in embeddings\n",
        "#         for i, line in enumerate(fEmbeddings):\n",
        "#             if i==0 and self.embedding == \"fastText\":\n",
        "#                 continue\n",
        "                \n",
        "#             split = line.strip().split(\" \") # removes leading and trailing chars and splits into list of single values\n",
        "#             word = split[0]  # embedding word entry\n",
        "\n",
        "#             if len(word2Idx) == 0:  # add padding+unknown\n",
        "#                 word2Idx[\"PADDING_TOKEN\"] = len(word2Idx)\n",
        "#                 vector = np.zeros(len(split) - 1)  # zero vector for 'PADDING' word\n",
        "#                 self.wordEmbeddings.append(vector)\n",
        "\n",
        "#                 word2Idx[\"UNKNOWN_TOKEN\"] = len(word2Idx)\n",
        "#                 vector = np.random.uniform(-0.25, 0.25, len(split) - 1)  # zero vector for 'PADDING' word\n",
        "#                 self.wordEmbeddings.append(vector)\n",
        "\n",
        "#             if split[0].lower() in words:\n",
        "#                 vector = np.array([float(num) for num in split[1:]])\n",
        "#                 self.wordEmbeddings.append(vector)  # word embedding vector\n",
        "#                 word2Idx[split[0]] = len(word2Idx)  # corresponding word dict; increments by 1 for each word\n",
        "\n",
        "#         self.wordEmbeddings = np.array(self.wordEmbeddings)\n",
        "\n",
        "        # dictionary of all possible characters\n",
        "        self.char2Idx = {\"PADDING\": 0, \"UNKNOWN\": 1}\n",
        "        for c in \" 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ.,-_()[]{}!?:;#'\\\"/\\\\%$`&=*+@^~|<>\":\n",
        "            self.char2Idx[c] = len(self.char2Idx) # 2,3,4 ...\n",
        "\n",
        "        # format: [[wordindices], [caseindices], [padded word indices], [label indices]]\n",
        "        self.train_set = padding(createMatrices(self.trainSentences, self.label2Idx, case2Idx, self.char2Idx))\n",
        "        self.dev_set = padding(createMatrices(self.devSentences, self.label2Idx, case2Idx, self.char2Idx))\n",
        "        self.test_set = padding(createMatrices(self.testSentences, self.label2Idx, case2Idx, self.char2Idx))\n",
        "\n",
        "        self.idx2Label = {v: k for k, v in self.label2Idx.items()}  # index to label(reverted)\n",
        "                                                                \n",
        "                                                                \n",
        "    def createBatches(self):\n",
        "        \n",
        "        \"\"\"Create batches\"\"\"\n",
        "        self.train_batch, self.train_batch_len = createBatches(self.train_set)\n",
        "        self.dev_batch, self.dev_batch_len = createBatches(self.dev_set)\n",
        "        self.test_batch, self.test_batch_len = createBatches(self.test_set)\n",
        "#         self.dev_batch, self.dev_batch_len = createBatchesNonTrain(self.dev_set)\n",
        "#         self.test_batch, self.test_batch_len = createBatchesNonTrain(self.test_set)\n",
        "        \n",
        "    def tag_dataset(self, dataset, model):\n",
        "        \"\"\"Tag data with numerical values\"\"\"\n",
        "        \n",
        "        #nTODO; check if labels are numeric\n",
        "        correctLabels = []\n",
        "        predLabels = []\n",
        "        for i in dataset.keys():\n",
        "          key = str(i)\n",
        "#           print(\"I: {}\".format(i))\n",
        "          if int(i) ==1:\n",
        "            continue\n",
        "          data = dataset[key]\n",
        "          tokens = []\n",
        "          tl = []\n",
        "          caseing = []\n",
        "          char = []\n",
        "          tokens_length = []\n",
        "          labels = []\n",
        "          for dt in data:\n",
        "#             print(\"DT: {}\".format(dt))\n",
        "            t, c, ch, l, _ = dt\n",
        "#             if len(c)==1 or len(t)==1:\n",
        "#               continue\n",
        "              \n",
        "#             print(\"Single token: {}-{}\".format(len(c), t))\n",
        "#             print(\"Single labels: {}\".format(l))\n",
        "#             if len(t)<=1:\n",
        "# #               continue\n",
        "#             print(\"T: {}\".format(t))\n",
        "#             print(t.split(' '))\n",
        "#             t = t.split(' ')  # moze tego nie trzeba\n",
        "          \n",
        "            t = np.expand_dims(t, -1)\n",
        "            l = np.expand_dims(l, -1)\n",
        "#             t = tf.reshape(t, [-1])\n",
        "      \n",
        "#             t = np.expand_dims(t.split(' '), -1)\n",
        "#             c = np.expand_dims(c, -1)\n",
        "            tokens.append(t)\n",
        "            caseing.append(c)\n",
        "            char.append(ch)\n",
        "            labels.append(l)\n",
        "            tokens_length.append(tl)\n",
        "            \n",
        "          tokens_in = np.asarray(tokens)\n",
        "          caseing_in = np.asarray(caseing)\n",
        "          char_in = np.asarray(char)\n",
        "#           labels_in = np.asarray(labels)\n",
        "          tokens_len_in = np.asarray(tokens_length)\n",
        "#           print(\"TOKENS_IN: {}\".format(tokens_in))\n",
        "#           print(\"LABELS_IN: {}\".format(labels_in))\n",
        "        \n",
        "#           print(\"TAG Tokens size: {}\".format(tokens_in.shape))\n",
        "#           if tokens_in.shape == (1,1):\n",
        "#             print(\"Tokens shape (1,1): {}\".format(tokens_in))\n",
        "#             continue\n",
        "#           print(\"TAG Labels size: {}\".format(labels_in.shape))\n",
        "#           print(\"TAG Caseing size: {}\".format(caseing_in.shape))\n",
        "#           print(\"Tokens: {}\".format(tokens_in))\n",
        "\n",
        "\n",
        "######################## TUTAJ ######################33\n",
        "          # daje shape (1,1) i się wykrzacza dla arraya z jednym zdaniem\n",
        "        \n",
        "  \n",
        "#           print(\"Shapes test: {} {} {}\".format(tokens_in.shape, caseing_in.shape, char_in.shape))\n",
        "          if tokens_in.shape[0] >1 and tokens_in.shape[1] >1:\n",
        "            pred = model.predict([tokens_in, caseing_in, char_in], verbose=False)[0]\n",
        "            pred = pred.argmax(axis=-1)  # Predict the classes\n",
        "            correctLabels.append(labels)\n",
        "            predLabels.append(pred)\n",
        "          \n",
        "          \n",
        "        return predLabels, correctLabels\n",
        "      \n",
        "      \n",
        "      \n",
        "#         for i, data in enumerate(dataset):\n",
        "#             tokens, casing, char, labels, _ = data\n",
        "#             if len(tokens)<=1:\n",
        "#               continue\n",
        "#             t = np.expand_dims(tokens, -1)\n",
        "#             tokens = np.asarray(t)\n",
        "\n",
        "#             # print(\"TOKEN: {}\".format(t))\n",
        "\n",
        "#             l = np.expand_dims(labels, -1)\n",
        "#             labels = np.asarray(l)\n",
        "            \n",
        "            \n",
        "# #             tokens = np.asarray([tokens])\n",
        "#             print(\"TAG TOKENS: {}\".format(tokens))\n",
        "#             casing = np.asarray([casing])\n",
        "#             char = np.asarray([char])\n",
        "#             pred = model.predict([tokens, casing, char], verbose=False)[0]\n",
        "#             pred = pred.argmax(axis=-1)  # Predict the classes\n",
        "#             correctLabels.append(labels)\n",
        "#             predLabels.append(pred)\n",
        "#         return predLabels, correctLabels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#         correctLabels = []\n",
        "#         predLabels = []\n",
        "#         # ToDO: only training data as sentences\n",
        "#         # ToDO: change for iteration through dict!\n",
        "#         for i in dataset.keys():\n",
        "#           key = str(i)\n",
        "#           data = dataset[key]\n",
        "#           for dt in data:\n",
        "#             ################################################################\n",
        "#             # sentences or tokens here!?\n",
        "#             ################################################################\n",
        "#             tokens, casing, char, labels, _ = dt\n",
        "# #             tokens = np.asarray([tokens])\n",
        "#             casing = np.asarray([casing])\n",
        "#             char = np.asarray([char])\n",
        "#             print(\"TAGGED tokens: {}\".format(tokens))\n",
        "#             pred = model.predict([tokens, casing, char], verbose=False, batch_size=len(tokens))[0]\n",
        "#             pred = pred.argmax(axis=-1)  # Predict the classes\n",
        "#             correctLabels.append(labels)\n",
        "#             predLabels.append(pred)\n",
        "#         return predLabels, correctLabels\n",
        "    \n",
        "    \n",
        "\n",
        "    def ELMoEmbedding(self, tokens_input):\n",
        "        # ToDO: pojedyncze zdanie na inpucie - lista słów (stringi)\n",
        "        #       zdania na inpucie - lista list \n",
        "        # zdefiniować input jako tokeny!\n",
        "        \"\"\" Return elmo embedding using tf_hub \"\"\"\n",
        "        elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)\n",
        "        # signature points to the purpose of why we would like to use the modules\n",
        "        # as_dict=True needed to output word embeddings instead of defualtss\n",
        "#         return elmo_model(tf.cast(tokens_input, tf.string), signature=\"default\", as_dict=True)['elmo']  #[\"word_emb\"]  #[\"default\"]  #[\"word_emb\"]\n",
        "\n",
        "#         return elmo_model(tf.cast(tokens_input, dtype=tf.string), signature=\"default\", as_dict=True)['elmo']  #[\"word_emb\"]  #[\"default\"]  #[\"word_emb\"]\n",
        "#         return elmo_model(tf.reshape(tf.cast(tokens_input, tf.string), [-1]), signature=\"default\", as_dict=True)['elmo']  #[\"word_emb\"]  #[\"default\"]  #[\"word_emb\"]\n",
        "\n",
        "        return elmo_model(tf.squeeze(tf.cast(tokens_input, tf.string)), signature=\"default\", as_dict=True)['elmo']  #[\"word_emb\"]  #[\"default\"]  #[\"word_emb\"]\n",
        "#         return elmo_model(tf.cast(tokens_input, tf.string), signature=\"default\", as_dict=True)['elmo']  #[\"word_emb\"]  #[\"default\"]  #[\"word_emb\"]\n",
        "\n",
        "#         return elmo_model(inputs={\"tokens\": tokens_input, \"sequence_len\": tokens_length}, signature=\"tokens\", as_dict=True)[\"word_emb\"]\n",
        "#       return elmo_model(x, signature=\"default\", as_dict=True)[\"word_emb\"]\n",
        "  \n",
        "    def buildModel(self):\n",
        "        \"\"\"Model layers\"\"\"\n",
        "\n",
        "        # character input\n",
        "        character_input = Input(shape=(None, 52,), name=\"Character_input\")  #input N sentences, each 52 chras length\n",
        "        embed_char_out = TimeDistributed(\n",
        "            Embedding(len(self.char2Idx),self.char_embedding_size, embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name=\"Character_embedding\")(\n",
        "            character_input)\n",
        "\n",
        "        dropout = Dropout(self.dropout)(embed_char_out)\n",
        "\n",
        "        # CNN\n",
        "        conv1d_out = TimeDistributed(Conv1D(kernel_size=self.conv_size, filters=30, padding='same', activation='tanh', strides=1), name=\"Convolution\")(dropout)\n",
        "        maxpool_out = TimeDistributed(MaxPooling1D(52), name=\"Maxpool\")(conv1d_out)  # pool_size=52: max sentence length\n",
        "        char = TimeDistributed(Flatten(), name=\"Flatten\")(maxpool_out)\n",
        "        char = Dropout(self.dropout)(char)\n",
        "\n",
        "        # word-level input\n",
        "        # input of N-dimensional vectors (1st arg in shape points to the size of input vectors)\n",
        "        words_input = Input(shape=(None, ), dtype=tf.string, name='words_input')\n",
        "        # model takes first dimension as number of examplese and second as the size of each example\n",
        "#         tokens_length = Input(shape=(None, None, ), name='tokens_length_input')  # co z data type\n",
        "#         print(\"After words input\")\n",
        "        # ToDO: Lambda powinna zwrócić odpowiedni rozmiar!\n",
        "#         words = self.ELMoEmbedding(words_input, tokens_length)\n",
        "        words = Lambda(self.ELMoEmbedding, output_shape=(None, 1024))(words_input)\n",
        "#         words_input = Input(shape=(None,), dtype='int32', name='words_input')\n",
        "#         words = Embedding(input_dim=self.wordEmbeddings.shape[0], output_dim=self.wordEmbeddings.shape[1], weights=[self .wordEmbeddings],\n",
        "#                           trainable=False)(words_input)  # trainable=False since we provide word embeddings\n",
        "#         print(\"After: {}\".format(words))\n",
        "\n",
        "        # case-info input\n",
        "        casing_input = Input(shape=(None,), dtype='int32', name='casing_input')\n",
        "        casing = Embedding(output_dim=self.caseEmbeddings.shape[1], input_dim=self.caseEmbeddings.shape[0], weights=[self.caseEmbeddings],\n",
        "                           trainable=False)(casing_input)  ## trainable=False since we provide case embeddings\n",
        "       \n",
        "      \n",
        "#         print(\"SIZES FOR CONCATENATION: {} {} {}\".format(words.shape, char.shape, casing.shape))\n",
        "        # concat & BLSTM\n",
        "#         print(\"DIMENSIONS: {}\".format(tf.shape(words_input)))\n",
        "              \n",
        "        output = concatenate([words, casing, char])\n",
        "#         output = concatenate([tf.reshape(words, \n",
        "#                                   [len(words), 52, 1024]), casing, char])\n",
        "        output = Bidirectional(LSTM(self.lstm_state_size, \n",
        "                                    return_sequences=True, \n",
        "                                    dropout=self.dropout,                        # on input to each LSTM block\n",
        "                                    recurrent_dropout=self.dropout_recurrent     # on recurrent input signal\n",
        "                                   ), name=\"BLSTM\")(output)\n",
        "        output = TimeDistributed(Dense(len(self.label2Idx), activation='softmax'),name=\"Softmax_layer\")(output)\n",
        "\n",
        "        # set up model\n",
        "\n",
        "        self.model = Model(inputs=[words_input, casing_input, character_input], outputs=[output])\n",
        "        \n",
        "        for layer in self.model.layers:\n",
        "            print(\"Layer {}: {}\".format(layer.name, layer.output_shape))\n",
        "        \n",
        "        \n",
        "        self.model.compile(loss='sparse_categorical_crossentropy', optimizer=self.optimizer)\n",
        "        \n",
        "        self.init_weights = self.model.get_weights()\n",
        "        \n",
        "        plot_model(self.model, to_file=os.path.join(LOCATION_POINTER, 'model_{}.png'.format(self.version)))\n",
        "        \n",
        "        print(\"Model built. Saved model.png\\n\")\n",
        "        \n",
        "    def train(self):\n",
        "        \"\"\"Default training\"\"\"\n",
        "\n",
        "        self.f1_test_history = []\n",
        "        self.f1_dev_history = []\n",
        "\n",
        "        for epoch in range(self.epochs):    \n",
        "            print(\"Epoch {}/{}\".format(epoch, self.epochs))\n",
        "            # batch: [word_indices, case_indices, char_indices]\n",
        "            print(\"Batch len: {}\".format(self.train_batch_len))\n",
        "            for i,batch in enumerate(iterate_minibatches(self.train_batch, self.train_batch_len)):\n",
        "                labels, tokens, casing, char, self.tokens_length = batch  \n",
        "#                 tokens = np.expand_dims(tokens[0], 1)\n",
        "#                 print(tokens)\n",
        "#                 print(\"length: {}\".format(len(tokens)))\n",
        "#                 print(\"TOKENS: {}\".format(tokens))\n",
        "#                 tokens_in = tf.reshape(tokens, [-1])\n",
        "#                 print(labels)\n",
        "#                 print(tokens[:5])\n",
        "#                 print(\"before train on batch - i: {}\".format(i))\n",
        "                if len(tokens) <= 1:\n",
        "                  continue\n",
        "#                 if i==55 or i ==2:\n",
        "#                   print(len(tokens), len(labels))\n",
        "#                 print(\"Shapes: {} {} {}\".format(tokens.shape, casing.shape, char.shape))\n",
        "                self.model.train_on_batch([tokens, casing, char], labels)\n",
        "#                 print(\"after train on batch - i: {}\".format(i))\n",
        "\n",
        "\n",
        "            # compute F1 scores\n",
        "            predLabels, correctLabels = self.tag_dataset(self.test_batch, self.model)\n",
        "            pre_test, rec_test, f1_test = compute_f1(predLabels, correctLabels, self.idx2Label)\n",
        "            self.f1_test_history.append(f1_test)\n",
        "            print(\"f1 test \", round(f1_test, 4))\n",
        "\n",
        "            predLabels, correctLabels = self.tag_dataset(self.dev_batch, self.model)\n",
        "            pre_dev, rec_dev, f1_dev = compute_f1(predLabels, correctLabels, self.idx2Label)\n",
        "            self.f1_dev_history.append(f1_dev)\n",
        "            print(\"f1 dev \", round(f1_dev, 4), \"\\n\")\n",
        "            \n",
        "        print(\"Final F1 test score: \", f1_test)\n",
        "            \n",
        "        print(\"Training finished.\")\n",
        "            \n",
        "        # save model\n",
        "        self.modelName = \"{}_{}_{}_{}_{}_{}_{}_{}_{}_{}\".format(self.epochs, \n",
        "                                                        self.dropout, \n",
        "                                                        self.dropout_recurrent, \n",
        "                                                        self.lstm_state_size,\n",
        "                                                        self.conv_size,\n",
        "                                                        self.learning_rate,\n",
        "                                                        self.char_embedding_size,\n",
        "                                                        self.optimizer.__class__.__name__,\n",
        "                                                        self.version,\n",
        "                                                        self.embedding\n",
        "                                                       )\n",
        "        \n",
        "        modelName = self.modelName + \".h5\"\n",
        "        self.model.save(os.path.join(LOCATION_POINTER, modelName))\n",
        "        print(\"Model weights saved.\")\n",
        "        \n",
        "        self.model.set_weights(self.init_weights)  # clear model\n",
        "        print(\"Model weights cleared.\")\n",
        "\n",
        "    def writeToFile(self):\n",
        "        \"\"\"Write output to file\"\"\"\n",
        "\n",
        "        output = np.matrix([[int(i) for i in range(self.epochs)], self.f1_test_history, self.f1_dev_history])\n",
        "\n",
        "        fileName = os.path.join(LOCATION_POINTER, self.modelName + \".txt\")\n",
        "        with open(fileName,'wb') as f:\n",
        "            for line in output:\n",
        "                np.savetxt(f, line, fmt='%.5f')\n",
        "                \n",
        "        print(\"Model performance written to file.\")\n",
        "        \n",
        "    def saveResults(self):\n",
        "        plt.plot(cnn_blstm.f1_test_history, label = \"F1 test\")\n",
        "        plt.plot(cnn_blstm.f1_dev_history, label = \"F1 dev\")\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"F1 score\")\n",
        "        plt.legend()\n",
        "        plt.savefig(os.path.join(LOCATION_POINTER, self.modelName + \".png\"))\n",
        "\n",
        "    print(\"Class initialised.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class initialised.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A0_c8WQ2BnBx",
        "colab_type": "code",
        "outputId": "71d09d15-0a59-4642-d7b0-9aac137b3a3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8831
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Construct and run model\"\"\"\n",
        "\n",
        "cnn_blstm = CNN_BLSTM(EPOCHS, DROPOUT, DROPOUT_RECURRENT, LSTM_STATE_SIZE, CONV_SIZE, LEARNING_RATE, OPTIMIZER, CHAR_EMBEDDING, VERSION, EMBEDDING)\n",
        "cnn_blstm.loadData()\n",
        "cnn_blstm.addCharInfo()\n",
        "cnn_blstm.embed()\n",
        "cnn_blstm.createBatches()\n",
        "cnn_blstm.buildModel()\n",
        "cnn_blstm.train()\n",
        "cnn_blstm.writeToFile()\n",
        "cnn_blstm.saveResults()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0402 22:27:39.396083 139698042873728 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer Character_input: (None, None, 52)\n",
            "Layer Character_embedding: (None, None, 52, 30)\n",
            "Layer dropout_5: (None, None, 52, 30)\n",
            "Layer Convolution: (None, None, 52, 30)\n",
            "Layer Maxpool: (None, None, 1, 30)\n",
            "Layer words_input: (None, None)\n",
            "Layer casing_input: (None, None)\n",
            "Layer Flatten: (None, None, 30)\n",
            "Layer lambda_3: (None, None, 1024)\n",
            "Layer embedding_6: (None, None, 8)\n",
            "Layer dropout_6: (None, None, 30)\n",
            "Layer concatenate_3: (None, None, 1062)\n",
            "Layer BLSTM: (None, None, 550)\n",
            "Layer Softmax_layer: (None, None, 9)\n",
            "Model built. Saved model.png\n",
            "\n",
            "Epoch 0/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 1/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 2/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 3/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 4/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 5/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 6/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 7/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 8/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 9/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 10/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 11/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 12/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 13/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 14/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 15/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 16/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 17/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 18/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 19/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 20/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 21/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 22/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 23/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 24/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 25/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 26/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 27/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 28/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 29/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 30/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 31/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 32/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 33/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 34/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 35/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 36/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 37/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 38/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 39/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 40/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 41/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 42/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 43/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 44/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 45/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 46/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 47/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 48/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 49/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 50/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 51/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 52/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 53/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 54/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 55/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 56/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 57/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 58/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 59/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 60/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 61/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 62/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 63/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 64/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 65/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 66/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 67/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 68/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 69/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 70/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 71/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 72/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 73/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 74/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 75/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 76/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 77/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 78/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Epoch 79/80\n",
            "Batch len: dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '62', '67', '78', '113'])\n",
            "f1 test  0\n",
            "f1 dev  0 \n",
            "\n",
            "Final F1 test score:  0\n",
            "Training finished.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1f8e2a94c0f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcnn_blstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateBatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcnn_blstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcnn_blstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mcnn_blstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteToFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcnn_blstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-ef02474a17ed>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mmodelName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCATION_POINTER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model weights saved.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0m_serialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_serialize_model\u001b[0;34m(model, f, include_optimizer)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_json_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mget_json_type\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not JSON Serializable: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Not JSON Serializable: <dtype: 'string'>"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_b5062mdw19j",
        "colab_type": "code",
        "outputId": "2d61559b-b313-45de-ead6-6f4e9989adc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "sentences = [ 'he said further scientific study was required and if it was found that action was needed it should be taken by the european union .'\n",
        " ,'he said no scientific study was required and if it was found that action was needed it should be taken by the european union .']\n",
        "sentences = np.asarray(sentences)\n",
        "# res = tf.reshape(sentences, [-1])\n",
        "print(res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Reshape:0\", shape=(2,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "08SgGkR6nMn8",
        "colab_type": "code",
        "outputId": "ddf1b0e2-83ba-468e-ce6b-540b119df007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)\n",
        "embeddings = elmo(tf.squeeze(tf.cast(sentences, tf.string)),\n",
        "signature=\"default\",\n",
        "as_dict=True)[\"elmo\"]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0330 19:08:53.286401 140299740088192 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "BBTsAMtlAXaO",
        "colab_type": "code",
        "outputId": "3bad8bfe-9aae-40db-e6ef-900a96405438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "tf.squeeze(tf.cast(sentences, tf.string))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Squeeze_1:0' shape=(2,) dtype=string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "m_f7uhqhnRHz",
        "colab_type": "code",
        "outputId": "e61fcfa6-cf0e-4367-f4ba-23d8000c9849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(embeddings)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"module_4_apply_default/aggregation/mul_3:0\", shape=(2, 25, 1024), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8HLM7vvqnSgL",
        "colab_type": "code",
        "outputId": "c5cb0cb7-cbeb-4d09-f1cb-42c188f43636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "def load_data(vocab_size, max_len):\n",
        "    \"\"\"\n",
        "        Loads the keras imdb dataset\n",
        "\n",
        "        Args:\n",
        "            vocab_size = {int} the size of the vocabulary\n",
        "            max_len = {int} the maximum length of input considered for padding\n",
        "\n",
        "        Returns:\n",
        "            X_train = tokenized train data\n",
        "            X_test = tokenized test data\n",
        "\n",
        "    \"\"\"\n",
        "    INDEX_FROM = 3\n",
        "\n",
        "    (X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size, index_from=INDEX_FROM)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "io8sFwJeTeCA",
        "colab_type": "code",
        "outputId": "974a873e-dfbe-41ef-d89f-d61edf692588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "    x_train,x_test,y_train,y_test = load_data(10000, 200)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vEvl1uoITxdw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def data_prep_ELMo(train_x, train_y, test_x, test_y, max_len):\n",
        "    INDEX_FROM = 3\n",
        "    train_text,train_label,test_text,test_label = data_prep_ELMo(x_train,y_train,x_test,y_test,200)\n",
        "    word_to_index = {k: (v + INDEX_FROM) for k, v in word_to_index.items()}\n",
        "\n",
        "    word_to_index[\"<START>\"] = 1\n",
        "    word_to_index[\"<UNK>\"] = 2\n",
        "\n",
        "    index_to_word = {v: k for k, v in word_to_index.items()}\n",
        "\n",
        "    sentences = []\n",
        "    for i in range(len(train_x)):\n",
        "        temp = [index_to_word[ids] for ids in train_x[i]]\n",
        "        sentences.append(temp)\n",
        "\n",
        "    test_sentences = []\n",
        "    for i in range(len(test_x)):\n",
        "        temp = [index_to_word[ids] for ids in test_x[i]]\n",
        "        test_sentences.append(temp)\n",
        "\n",
        "        \n",
        "    print(\"first: {}\".format(' '.join(sentences[0][:max_len])))\n",
        "    train_text = [' '.join(sentences[i][:max_len]) for i in range(len(sentences))]\n",
        "    train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
        "    train_label = train_y.tolist()\n",
        "\n",
        "    test_text = [' '.join(test_sentences[i][:500]) for i in range(len(test_sentences))]\n",
        "    test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
        "    test_label = test_y.tolist()\n",
        "\n",
        "    return train_text, train_label, test_text, test_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kr9oMhy-Vehn",
        "colab_type": "code",
        "outputId": "f6bf5ae8-07fe-4706-c3f4-35941a070f0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "train_text,train_label,test_text,test_label = data_prep_ELMo(x_train, y_train,x_test, y_test, 200)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RecursionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-93b76e06fbb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_prep_ELMo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-bdac3fad809f>\u001b[0m in \u001b[0;36mdata_prep_ELMo\u001b[0;34m(train_x, train_y, test_x, test_y, max_len)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_prep_ELMo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mINDEX_FROM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_prep_ELMo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mword_to_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mINDEX_FROM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "... last 1 frames repeated, from the frame below ...\n",
            "\u001b[0;32m<ipython-input-24-bdac3fad809f>\u001b[0m in \u001b[0;36mdata_prep_ELMo\u001b[0;34m(train_x, train_y, test_x, test_y, max_len)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_prep_ELMo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mINDEX_FROM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_prep_ELMo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mword_to_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mINDEX_FROM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5WAGAqshUKjI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_text,train_label,test_text,test_label = data_prep_ELMo(x_train,y_train,x_test,y_test,200)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oFsIAY6EUYWA",
        "colab_type": "code",
        "outputId": "ad24b3d7-f330-4cef-f626-fad61da0bf8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "print(train_text[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZP5gZkj6R8Kv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}